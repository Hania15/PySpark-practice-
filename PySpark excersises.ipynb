{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9260b6b5-6876-4104-9e68-ff0e190bd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a792de46-2c10-431b-902b-e2968dc81943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d62893d-4eae-4092-bf64-d1f567344e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b01967-5cfc-4d13-8db6-8e31b575ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddec3f2-e25b-420e-88cd-025d697d125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/16 21:04:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#creating a spark session \n",
    "spark = SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "990f6275-8bc0-4941-b27f-eaa319d0e3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://air-hania:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff5a01dd880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "778d4161-0fdb-49de-aee0-2f5bbb4a4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac82ada9-2e42-4b8e-a22f-977b8daeb48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df in pyspark shows the column number and what values are included in those columns\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4207dd72-266f-4c8c-8d8c-7d1f4810f748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        896|       1|\n",
      "|        897|       0|\n",
      "|        898|       1|\n",
      "|        899|       0|\n",
      "|        900|       1|\n",
      "|        901|       0|\n",
      "|        902|       0|\n",
      "|        903|       1|\n",
      "|        904|       1|\n",
      "|        905|       0|\n",
      "|        906|       1|\n",
      "|        907|       1|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       0|\n",
      "|        911|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading the dataset\n",
    "#how to read data using pyspark in more common way\n",
    "spark.read.option('header', 'true').csv('titanic.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69002aa7-9f41-4dcb-9588-15ab4f51a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d173d8af-991e-49bb-98e1-7e3e6d648038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check if we are reading this particular dataframe using pyspark\n",
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "984041f6-806a-4a2b-8b09-f9cdd49dfb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Survived: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6395210a-00b9-4bf6-9b47-8a3611bbf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically check the data type in schemas\n",
    "\n",
    "df_pyspark = spark.read.option('header', 'true').csv('titanic.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffd8158-869d-4806-a0a8-1089a7849f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9143f6a8-1e07-4233-806e-375e1951a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId', 'Survived']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the columns\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7ccb179-fd2a-44bc-a64f-db565bad349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PassengerId=892, Survived=0),\n",
       " Row(PassengerId=893, Survived=0),\n",
       " Row(PassengerId=894, Survived=0),\n",
       " Row(PassengerId=895, Survived=0),\n",
       " Row(PassengerId=896, Survived=1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb876af3-f29d-45f4-a1fa-a8503a91a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        896|       1|\n",
      "|        897|       0|\n",
      "|        898|       1|\n",
      "|        899|       0|\n",
      "|        900|       1|\n",
      "|        901|       0|\n",
      "|        902|       0|\n",
      "|        903|       1|\n",
      "|        904|       1|\n",
      "|        905|       0|\n",
      "|        906|       1|\n",
      "|        907|       1|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       0|\n",
      "|        911|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7059449-ee21-474d-bf37-39289ad4a4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|PassengerId|\n",
      "+-----------+\n",
      "|        892|\n",
      "|        893|\n",
      "|        894|\n",
      "|        895|\n",
      "|        896|\n",
      "|        897|\n",
      "|        898|\n",
      "|        899|\n",
      "|        900|\n",
      "|        901|\n",
      "|        902|\n",
      "|        903|\n",
      "|        904|\n",
      "|        905|\n",
      "|        906|\n",
      "|        907|\n",
      "|        908|\n",
      "|        909|\n",
      "|        910|\n",
      "|        911|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('PassengerId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b7db974-913e-4e02-8704-aa29f70a2e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('PassengerId'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2333e051-cdc4-4a52-8489-61ca3318c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        896|       1|\n",
      "|        897|       0|\n",
      "|        898|       1|\n",
      "|        899|       0|\n",
      "|        900|       1|\n",
      "|        901|       0|\n",
      "|        902|       0|\n",
      "|        903|       1|\n",
      "|        904|       1|\n",
      "|        905|       0|\n",
      "|        906|       1|\n",
      "|        907|       1|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       0|\n",
      "|        911|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['PassengerId', 'Survived']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f41eb52-3fa2-4076-8126-ca15638c8848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PassengerId', 'int'), ('Survived', 'int')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffee4b20-bba3-4e4d-8a9a-2bfddbb56398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+\n",
      "|summary|       PassengerId|           Survived|\n",
      "+-------+------------------+-------------------+\n",
      "|  count|               418|                418|\n",
      "|   mean|            1100.5| 0.3660287081339713|\n",
      "| stddev|120.81045760473994|0.48229469397427244|\n",
      "|    min|               892|                  0|\n",
      "|    max|              1309|                  1|\n",
      "+-------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69bad6ef-68c2-4cbb-9f91-8b17ba345518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbaf262c-8ff0-497c-8142-b4dd24718130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------+\n",
      "|PassengerId|Survived|Survived2|\n",
      "+-----------+--------+---------+\n",
      "|        892|       0|       no|\n",
      "|        893|       0|       no|\n",
      "|        894|       0|       no|\n",
      "|        895|       0|       no|\n",
      "|        896|       1|      yes|\n",
      "|        897|       0|       no|\n",
      "|        898|       1|      yes|\n",
      "|        899|       0|       no|\n",
      "|        900|       1|      yes|\n",
      "|        901|       0|       no|\n",
      "|        902|       0|       no|\n",
      "|        903|       1|      yes|\n",
      "|        904|       1|      yes|\n",
      "|        905|       0|       no|\n",
      "|        906|       1|      yes|\n",
      "|        907|       1|      yes|\n",
      "|        908|       0|       no|\n",
      "|        909|       0|       no|\n",
      "|        910|       0|       no|\n",
      "|        911|       0|       no|\n",
      "+-----------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding new columns to df\n",
    "df_pyspark.withColumn('Survived2', when(df_pyspark['Survived']== 1, 'yes').otherwise('no')).show()\n",
    "df_pyspark2 = df_pyspark.withColumn('Survived2', when(df_pyspark['Survived']== 1, 'yes').otherwise('no'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b22ede93-b1a1-4530-9e34-60b2200385ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        896|       1|\n",
      "|        897|       0|\n",
      "|        898|       1|\n",
      "|        899|       0|\n",
      "|        900|       1|\n",
      "|        901|       0|\n",
      "|        902|       0|\n",
      "|        903|       1|\n",
      "|        904|       1|\n",
      "|        905|       0|\n",
      "|        906|       1|\n",
      "|        907|       1|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       0|\n",
      "|        911|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the column\n",
    "\n",
    "df_pyspark2.drop('Survived2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f2a2b6b-a5e8-4628-8228-9ba16a262e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|PassengerId|Survived|\n",
      "+-----------+--------+\n",
      "|        892|       0|\n",
      "|        893|       0|\n",
      "|        894|       0|\n",
      "|        895|       0|\n",
      "|        897|       0|\n",
      "|        899|       0|\n",
      "|        901|       0|\n",
      "|        902|       0|\n",
      "|        905|       0|\n",
      "|        908|       0|\n",
      "|        909|       0|\n",
      "|        910|       0|\n",
      "|        911|       0|\n",
      "|        912|       0|\n",
      "|        913|       0|\n",
      "|        917|       0|\n",
      "|        919|       0|\n",
      "|        921|       0|\n",
      "|        922|       0|\n",
      "|        923|       0|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['PassengerId'] > 890) & (df_pyspark['Survived'] == '0')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6753b82c-8ac1-4616-b4cc-b0d082a66c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "count_of_filtered_value = df_pyspark.filter((df_pyspark['PassengerId'] > 890) & (df_pyspark['Survived'] == '0')).count()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec124130-faac-43bf-a273-381226ade1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: string, Survived: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d43521-5e6d-4dcf-9d28-81e1cb1800de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
